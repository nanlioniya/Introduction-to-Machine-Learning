{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install opencv-python\n","!pip install numpy\n","!pip install torch"]},{"cell_type":"code","execution_count":247,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:45:08.288956Z","iopub.status.busy":"2022-12-18T08:45:08.288555Z","iopub.status.idle":"2022-12-18T08:45:08.294867Z","shell.execute_reply":"2022-12-18T08:45:08.293840Z","shell.execute_reply.started":"2022-12-18T08:45:08.288916Z"},"trusted":true},"outputs":[],"source":["import csv\n","import cv2\n","import numpy as np\n","import random\n","import os\n","\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":248,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:45:22.602023Z","iopub.status.busy":"2022-12-18T08:45:22.601611Z","iopub.status.idle":"2022-12-18T08:45:22.607729Z","shell.execute_reply":"2022-12-18T08:45:22.606491Z","shell.execute_reply.started":"2022-12-18T08:45:22.601990Z"},"trusted":true},"outputs":[],"source":["TRAIN_PATH = \"/kaggle/input/captcha-hacker/train\"\n","TEST_PATH = \"/kaggle/input/captcha-hacker/test\"\n","# device = \"cpu\"\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# try device = \"cuda\" \n","# and change your settings/accelerator to GPU if you want it to run faster"]},{"cell_type":"code","execution_count":249,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:45:24.888756Z","iopub.status.busy":"2022-12-18T08:45:24.888396Z","iopub.status.idle":"2022-12-18T08:45:24.917232Z","shell.execute_reply":"2022-12-18T08:45:24.916302Z","shell.execute_reply.started":"2022-12-18T08:45:24.888725Z"},"trusted":true},"outputs":[],"source":["train_data = []\n","val_data = []\n","test_data = []\n","\n","with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n","    for row in csv.reader(csvfile, delimiter=','):\n","        if random.random() < 0.7:\n","            train_data.append(row)\n","        else:\n","            val_data.append(row)\n","\n","with open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n","    for row in csv.reader(csvfile, delimiter=','):\n","        test_data.append(row)"]},{"cell_type":"code","execution_count":250,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:45:27.855300Z","iopub.status.busy":"2022-12-18T08:45:27.854761Z","iopub.status.idle":"2022-12-18T08:45:27.868716Z","shell.execute_reply":"2022-12-18T08:45:27.867339Z","shell.execute_reply.started":"2022-12-18T08:45:27.855265Z"},"trusted":true},"outputs":[],"source":["def horizonFlip(img):\n","    flip_img = np.zeros(img.shape, dtype=np.uint8)\n","    row_idx = 0\n","    for row in img:\n","        flip_img[row_idx] = row[::-1]\n","        row_idx += 1\n","    return flip_img\n","\n","def colorJittering(img):\n","    color_img = np.zeros(img.shape, dtype=np.uint8)\n","    for r in range(len(img)):\n","        for c in range(len(img[r])):\n","            color_img[r][c][:2] = img[r][c][:2]  # Turn off 'B' channel\n","    return color_img\n","\n","def noiseInjection(img):\n","    noise = np.random.normal(0, 8, img.shape)\n","    noise = np.array([int(n) for row in noise for col in row for n in col])\n","    noise = noise.reshape(img.shape)\n","    noise_img = img + noise\n","    noise_img[np.where(noise_img > 255)] = 255\n","    noise_img[np.where(noise_img < 0)] = 0\n","    return noise_img\n","\n","def dataAugmentation(x, y):\n","    aug_number = 4\n","    x_new = np.zeros(shape=(len(x) * aug_number, 32, 32, 1), dtype=np.uint8)\n","    y_new = np.zeros(shape=(len(y) * aug_number, len(y[0])), dtype=np.int64)\n","    for i in range(0, len(x) * aug_number, aug_number):\n","        index = i // aug_number\n","        y_new[i: i + aug_number] = y[index]\n","        \n","        #print(y_new[i: i + aug_number].shape) = (4, 1751)\n","        #print(y[index].shape) = (2,)\n","        \n","        x_new[i] = x[index]\n","        x_new[i + 1] = horizonFlip(x[index])\n","        x_new[i + 2] = colorJittering(x[index])\n","        x_new[i + 3] = noiseInjection(x[index])\n","    return x_new, y_new"]},{"cell_type":"code","execution_count":251,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:45:30.633166Z","iopub.status.busy":"2022-12-18T08:45:30.632778Z","iopub.status.idle":"2022-12-18T08:45:30.639990Z","shell.execute_reply":"2022-12-18T08:45:30.638854Z","shell.execute_reply.started":"2022-12-18T08:45:30.633135Z"},"trusted":true},"outputs":[],"source":["LETTERSTR = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n","\n","def encode(text):\n","    labellist = []\n","    for letter in text:\n","        num = LETTERSTR.find(letter)\n","        labellist.append(num)\n","    return labellist\n","\n","LETTERSTR_char = \"0,1,2,3,4,5,6,7,8,9,a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z\"\n","LETTERSTR_char = LETTERSTR_char.split(\",\")\n","LETTERSTR_index = [i for i in range(36)]\n","decode = dict(zip(LETTERSTR_index, LETTERSTR_char))"]},{"cell_type":"code","execution_count":252,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:45:44.139264Z","iopub.status.busy":"2022-12-18T08:45:44.138906Z","iopub.status.idle":"2022-12-18T08:45:44.151176Z","shell.execute_reply":"2022-12-18T08:45:44.150164Z","shell.execute_reply.started":"2022-12-18T08:45:44.139234Z"},"trusted":true},"outputs":[],"source":["def ExtractData(data, root, task_round):\n","    filenames = np.array([sample for sample in data if sample[0].startswith(task_round)])\n","    imgs_names = filenames[:, 0]\n","    label = filenames[:, 1]\n","    imgs = np.zeros(shape=(len(filenames), 32, 32, 1))\n","    labels = np.zeros(shape=(len(filenames), len(label[0])))\n","    for i in range(len(filenames)):\n","        tmp = cv2.imread(f\"{root}/{imgs_names[i]}\")\n","        tmp = cv2.resize(tmp, (32, 32))\n","        tmp = cv2.cvtColor(tmp, cv2.COLOR_BGR2GRAY)\n","        imgs[i] = np.expand_dims(tmp, axis=2)\n","        tmp_label = encode(label[i])\n","        labels[i] = np.array(tmp_label)\n","    return imgs_names, imgs, labels\n","\n","class TaskDataset(Dataset):\n","    def __init__(self, x_data, y_data, filenames, return_filename=False):\n","        x_data = x_data.astype('float32')\n","        x_data = x_data / 255.0\n","        self.x_data = torch.from_numpy(x_data).permute(0, 3, 1, 2) # (N, 1, 32, 32)\n","        self.y_data = torch.from_numpy(y_data) # (N, 1)\n","        self.filenames = filenames\n","        self.return_filename = return_filename\n","        \n","    def __getitem__(self, index):\n","        if self.return_filename:\n","            return self.x_data[index], self.filenames[index] # aug_num = 5\n","        else:\n","            return self.x_data[index], self.y_data[index]\n","        \n","    def __len__(self):\n","        return len(self.x_data)"]},{"cell_type":"code","execution_count":253,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:45:47.080751Z","iopub.status.busy":"2022-12-18T08:45:47.080390Z","iopub.status.idle":"2022-12-18T08:45:47.089189Z","shell.execute_reply":"2022-12-18T08:45:47.088115Z","shell.execute_reply.started":"2022-12-18T08:45:47.080720Z"},"trusted":true},"outputs":[],"source":["class Task1Dataset(Dataset):\n","    def __init__(self, data, root, return_filename=False):\n","        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n","        self.return_filename = return_filename\n","        self.root = root\n","    \n","    def __getitem__(self, index):\n","        filename, label = self.data[index]\n","        img = cv2.imread(f\"{self.root}/{filename}\")\n","        img = cv2.resize(img, (32, 32))\n","        \n","        img = torch.tensor(img).permute(2,0,1)\n","        if self.return_filename:\n","            return torch.FloatTensor((img - 128) / 128), filename\n","        else:\n","            return torch.FloatTensor((img - 128) / 128), int(label)\n","\n","    def __len__(self):\n","        return len(self.data)"]},{"cell_type":"code","execution_count":254,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:45:48.986336Z","iopub.status.busy":"2022-12-18T08:45:48.985975Z","iopub.status.idle":"2022-12-18T08:45:48.998756Z","shell.execute_reply":"2022-12-18T08:45:48.997316Z","shell.execute_reply.started":"2022-12-18T08:45:48.986307Z"},"trusted":true},"outputs":[],"source":["# task1 data processing\n","train_ds = Task1Dataset(train_data, root=TRAIN_PATH)\n","train_dl = DataLoader(train_ds, batch_size=40, num_workers=2, drop_last=True, shuffle=True)\n","\n","val_ds = Task1Dataset(val_data, root=TRAIN_PATH)\n","val_dl = DataLoader(val_ds, batch_size=40, num_workers=2, drop_last=False, shuffle=False)\n","\n","test_ds = Task1Dataset(test_data, root=TEST_PATH, return_filename=True)\n","test_dl = DataLoader(test_ds, batch_size=130, num_workers=2, drop_last=False, shuffle=False)"]},{"cell_type":"code","execution_count":255,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:45:50.855732Z","iopub.status.busy":"2022-12-18T08:45:50.855363Z","iopub.status.idle":"2022-12-18T08:45:50.872144Z","shell.execute_reply":"2022-12-18T08:45:50.871106Z","shell.execute_reply.started":"2022-12-18T08:45:50.855701Z"},"trusted":true},"outputs":[],"source":["class Model1(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # input size = (3, 32, 32)\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv2d(3, 64, kernel_size=3,\n","                                  stride=1, padding=1),\n","                        nn.BatchNorm2d(64),\n","                        nn.ReLU())\n","        self.conv2 = nn.Sequential(\n","                        nn.Conv2d(64, 64, kernel_size=3,\n","                                  stride=1, padding=1),\n","                        nn.BatchNorm2d(64),\n","                        nn.ReLU())\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=2)  # (64,16,16)\n","        self.dropout1 = nn.Dropout(p=0.2)\n","\n","        self.conv3 = nn.Sequential(\n","                        nn.Conv2d(64, 128, kernel_size=3,\n","                                  stride=1, padding=1),\n","                        nn.BatchNorm2d(128),\n","                        nn.ReLU())\n","        self.conv4 = nn.Sequential(\n","                        nn.Conv2d(128, 128, kernel_size=3,\n","                                  stride=1, padding=1),\n","                        nn.BatchNorm2d(128),\n","                        nn.ReLU())\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=2)  # (128,8,8)\n","        self.dropout2 = nn.Dropout(p=0.3)\n","\n","        self.conv5 = nn.Sequential(\n","                        nn.Conv2d(128, 128, kernel_size=3,\n","                                  stride=1, padding=1),\n","                        nn.BatchNorm2d(128),\n","                        nn.ReLU())\n","        self.conv6 = nn.Sequential(\n","                        nn.Conv2d(128, 128, kernel_size=3,\n","                                  stride=1, padding=1),\n","                        nn.BatchNorm2d(128),\n","                        nn.ReLU())\n","        self.maxpool3 = nn.MaxPool2d(kernel_size=2)  # (128,4,4)\n","        self.dropout3 = nn.Dropout(p=0.4)\n","\n","        # FC, input size = (16, 5, 5)\n","        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n","        self.relu3 = nn.ReLU()\n","        self.dropout4 = nn.Dropout(p=0.5)\n","        self.fc2 = nn.Linear(512, 10)\n","        self.output = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        out = self.dropout1(self.maxpool1(self.conv2(self.conv1(x))))\n","        out = self.dropout2(self.maxpool2(self.conv4(self.conv3(out))))\n","        out = self.dropout3(self.maxpool3(self.conv6(self.conv5(out))))\n","        out = torch.flatten(out, 1)  # from CNN to FCN\n","        out = self.output(self.fc2(self.dropout4(self.relu3(self.fc1(out)))))\n","        return out"]},{"cell_type":"code","execution_count":263,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:47:32.017164Z","iopub.status.busy":"2022-12-18T08:47:32.016380Z","iopub.status.idle":"2022-12-18T08:50:11.769354Z","shell.execute_reply":"2022-12-18T08:50:11.767284Z","shell.execute_reply.started":"2022-12-18T08:47:32.017118Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0]\n","accuracy (validation): tensor(0.0801, device='cuda:0')\n","Epoch [1]\n","accuracy (validation): tensor(0.1083, device='cuda:0')\n","Epoch [2]\n","accuracy (validation): tensor(0.2810, device='cuda:0')\n","Epoch [3]\n","accuracy (validation): tensor(0.4113, device='cuda:0')\n","Epoch [4]\n","accuracy (validation): tensor(0.5400, device='cuda:0')\n","Epoch [5]\n","accuracy (validation): tensor(0.5950, device='cuda:0')\n","Epoch [6]\n","accuracy (validation): tensor(0.6358, device='cuda:0')\n","Epoch [7]\n","accuracy (validation): tensor(0.6452, device='cuda:0')\n","Epoch [8]\n","accuracy (validation): tensor(0.6358, device='cuda:0')\n","Epoch [9]\n","accuracy (validation): tensor(0.8226, device='cuda:0')\n","Epoch [10]\n","accuracy (validation): tensor(0.8493, device='cuda:0')\n","Epoch [11]\n","accuracy (validation): tensor(0.9199, device='cuda:0')\n","Epoch [12]\n","accuracy (validation): tensor(0.9011, device='cuda:0')\n","Epoch [13]\n","accuracy (validation): tensor(0.9231, device='cuda:0')\n","Epoch [14]\n","accuracy (validation): tensor(0.8932, device='cuda:0')\n","Epoch [15]\n","accuracy (validation): tensor(0.9309, device='cuda:0')\n","Epoch [16]\n","accuracy (validation): tensor(0.9623, device='cuda:0')\n","Epoch [17]\n","accuracy (validation): tensor(0.9294, device='cuda:0')\n","Epoch [18]\n","accuracy (validation): tensor(0.9215, device='cuda:0')\n","Epoch [19]\n","accuracy (validation): tensor(0.9639, device='cuda:0')\n","Epoch [20]\n","accuracy (validation): tensor(0.9545, device='cuda:0')\n","Epoch [21]\n","accuracy (validation): tensor(0.9592, device='cuda:0')\n","Epoch [22]\n","accuracy (validation): tensor(0.9623, device='cuda:0')\n","Epoch [23]\n","accuracy (validation): tensor(0.9686, device='cuda:0')\n","Epoch [24]\n","accuracy (validation): tensor(0.9576, device='cuda:0')\n","Epoch [25]\n","accuracy (validation): tensor(0.9482, device='cuda:0')\n","Epoch [26]\n","accuracy (validation): tensor(0.9608, device='cuda:0')\n","Epoch [27]\n","accuracy (validation): tensor(0.9733, device='cuda:0')\n","Epoch [28]\n","accuracy (validation): tensor(0.9576, device='cuda:0')\n","Epoch [29]\n","accuracy (validation): tensor(0.9702, device='cuda:0')\n","Epoch [30]\n","accuracy (validation): tensor(0.9325, device='cuda:0')\n","Epoch [31]\n","accuracy (validation): tensor(0.9482, device='cuda:0')\n","Epoch [32]\n","accuracy (validation): tensor(0.9749, device='cuda:0')\n","Epoch [33]\n","accuracy (validation): tensor(0.9717, device='cuda:0')\n","Epoch [34]\n","accuracy (validation): tensor(0.9749, device='cuda:0')\n","Epoch [35]\n","accuracy (validation): tensor(0.9623, device='cuda:0')\n","Epoch [36]\n","accuracy (validation): tensor(0.9655, device='cuda:0')\n","Epoch [37]\n","accuracy (validation): tensor(0.9608, device='cuda:0')\n","Epoch [38]\n","accuracy (validation): tensor(0.9733, device='cuda:0')\n","Epoch [39]\n","accuracy (validation): tensor(0.9796, device='cuda:0')\n","Epoch [40]\n","accuracy (validation): tensor(0.9560, device='cuda:0')\n","Epoch [41]\n","accuracy (validation): tensor(0.9717, device='cuda:0')\n","Epoch [42]\n","accuracy (validation): tensor(0.9749, device='cuda:0')\n","Epoch [43]\n","accuracy (validation): tensor(0.9765, device='cuda:0')\n","Epoch [44]\n","accuracy (validation): tensor(0.9812, device='cuda:0')\n","Epoch [45]\n","accuracy (validation): tensor(0.9780, device='cuda:0')\n","Epoch [46]\n","accuracy (validation): tensor(0.9780, device='cuda:0')\n","Epoch [47]\n","accuracy (validation): tensor(0.9765, device='cuda:0')\n","Epoch [48]\n","accuracy (validation): tensor(0.9780, device='cuda:0')\n","Epoch [49]\n","accuracy (validation): tensor(0.9717, device='cuda:0')\n","Epoch [50]\n","accuracy (validation): tensor(0.9498, device='cuda:0')\n","Epoch [51]\n","accuracy (validation): tensor(0.9608, device='cuda:0')\n","Epoch [52]\n","accuracy (validation): tensor(0.9702, device='cuda:0')\n","Epoch [53]\n","accuracy (validation): tensor(0.9670, device='cuda:0')\n","Epoch [54]\n","accuracy (validation): tensor(0.9717, device='cuda:0')\n","Epoch [55]\n","accuracy (validation): tensor(0.9576, device='cuda:0')\n","Epoch [56]\n","accuracy (validation): tensor(0.9812, device='cuda:0')\n","Epoch [57]\n","accuracy (validation): tensor(0.9702, device='cuda:0')\n","Epoch [58]\n","accuracy (validation): tensor(0.9749, device='cuda:0')\n","Epoch [59]\n","accuracy (validation): tensor(0.9733, device='cuda:0')\n","Epoch [60]\n","accuracy (validation): tensor(0.9356, device='cuda:0')\n","Epoch [61]\n","accuracy (validation): tensor(0.9592, device='cuda:0')\n","Epoch [62]\n","accuracy (validation): tensor(0.9655, device='cuda:0')\n","Epoch [63]\n","accuracy (validation): tensor(0.9545, device='cuda:0')\n","Epoch [64]\n","accuracy (validation): tensor(0.9717, device='cuda:0')\n","Epoch [65]\n","accuracy (validation): tensor(0.9749, device='cuda:0')\n","Epoch [66]\n","accuracy (validation): tensor(0.9670, device='cuda:0')\n","Epoch [67]\n","accuracy (validation): tensor(0.9639, device='cuda:0')\n","Epoch [68]\n","accuracy (validation): tensor(0.9780, device='cuda:0')\n","Epoch [69]\n","accuracy (validation): tensor(0.9717, device='cuda:0')\n","Epoch [70]\n","accuracy (validation): tensor(0.9623, device='cuda:0')\n","Epoch [71]\n","accuracy (validation): tensor(0.9639, device='cuda:0')\n","Epoch [72]\n","accuracy (validation): tensor(0.9702, device='cuda:0')\n","Epoch [73]\n","accuracy (validation): tensor(0.9780, device='cuda:0')\n","Epoch [74]\n","accuracy (validation): tensor(0.9733, device='cuda:0')\n","Epoch [75]\n","accuracy (validation): tensor(0.9780, device='cuda:0')\n","Epoch [76]\n","accuracy (validation): tensor(0.9686, device='cuda:0')\n","Epoch [77]\n","accuracy (validation): tensor(0.9812, device='cuda:0')\n","Epoch [78]\n","accuracy (validation): tensor(0.9717, device='cuda:0')\n","Epoch [79]\n","accuracy (validation): tensor(0.9843, device='cuda:0')\n","Epoch [80]\n","accuracy (validation): tensor(0.9655, device='cuda:0')\n","Epoch [81]\n","accuracy (validation): tensor(0.9827, device='cuda:0')\n","Epoch [82]\n","accuracy (validation): tensor(0.9639, device='cuda:0')\n","Epoch [83]\n","accuracy (validation): tensor(0.9796, device='cuda:0')\n","Epoch [84]\n","accuracy (validation): tensor(0.9780, device='cuda:0')\n","Epoch [85]\n","accuracy (validation): tensor(0.9765, device='cuda:0')\n","Epoch [86]\n","accuracy (validation): tensor(0.9655, device='cuda:0')\n","Epoch [87]\n","accuracy (validation): tensor(0.9702, device='cuda:0')\n","Epoch [88]\n","accuracy (validation): tensor(0.9733, device='cuda:0')\n","Epoch [89]\n","accuracy (validation): tensor(0.9859, device='cuda:0')\n","Epoch [90]\n","accuracy (validation): tensor(0.9827, device='cuda:0')\n","Epoch [91]\n","accuracy (validation): tensor(0.9765, device='cuda:0')\n","Epoch [92]\n","accuracy (validation): tensor(0.9843, device='cuda:0')\n","Epoch [93]\n","accuracy (validation): tensor(0.9827, device='cuda:0')\n","Epoch [94]\n","accuracy (validation): tensor(0.9843, device='cuda:0')\n","Epoch [95]\n","accuracy (validation): tensor(0.9859, device='cuda:0')\n","Epoch [96]\n","accuracy (validation): tensor(0.9702, device='cuda:0')\n","Epoch [97]\n","accuracy (validation): tensor(0.9812, device='cuda:0')\n","Epoch [98]\n","accuracy (validation): tensor(0.9796, device='cuda:0')\n","Epoch [99]\n","accuracy (validation): tensor(0.9859, device='cuda:0')\n"]}],"source":["model = Model1().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","\n","for epoch in range(100):\n","    print(f\"Epoch [{epoch}]\")\n","    model.train()\n","    for image, label in train_dl:\n","        image = image.to(device)\n","        label = label.to(device)\n","        \n","        pred = model(image)\n","        loss = loss_fn(pred, label)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    sample_count = 0\n","    correct_count = 0\n","    model.eval()\n","    for image, label in val_dl:\n","        image = image.to(device)\n","        label = label.to(device)\n","        \n","        pred = model(image)\n","        loss = loss_fn(pred, label)\n","        \n","        pred = torch.argmax(pred, dim=1)\n","        \n","        sample_count += len(image)\n","        correct_count += (label == pred).sum()\n","        \n","    print(\"accuracy (validation):\", correct_count / sample_count)"]},{"cell_type":"code","execution_count":264,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:50:43.678485Z","iopub.status.busy":"2022-12-18T08:50:43.678082Z","iopub.status.idle":"2022-12-18T08:50:43.761725Z","shell.execute_reply":"2022-12-18T08:50:43.760785Z","shell.execute_reply.started":"2022-12-18T08:50:43.678450Z"},"trusted":true},"outputs":[],"source":["task1 = {'model': Model1(),\n","         'state_dict': model.state_dict(),\n","         'optimizer' : optimizer.state_dict()}\n","\n","torch.save(task1, 'task1.pth')"]},{"cell_type":"code","execution_count":265,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:50:46.469844Z","iopub.status.busy":"2022-12-18T08:50:46.468855Z","iopub.status.idle":"2022-12-18T08:50:50.543054Z","shell.execute_reply":"2022-12-18T08:50:50.541793Z","shell.execute_reply.started":"2022-12-18T08:50:46.469784Z"},"trusted":true},"outputs":[],"source":["# predict test1 write to csv\n","csv_writer = csv.writer(open('submission.csv', 'w', newline=''))\n","csv_writer.writerow([\"filename\", \"label\"])\n","\n","model.eval()\n","for image, filenames in test_dl:\n","    image = image.to(device)\n","    \n","    pred = model(image)\n","    pred = torch.argmax(pred, dim=1)\n","    \n","    for i in range(len(filenames)):\n","        csv_writer.writerow([filenames[i], str(pred[i].item())])"]},{"cell_type":"code","execution_count":266,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:51:06.731366Z","iopub.status.busy":"2022-12-18T08:51:06.730702Z","iopub.status.idle":"2022-12-18T08:51:16.004409Z","shell.execute_reply":"2022-12-18T08:51:16.003226Z","shell.execute_reply.started":"2022-12-18T08:51:06.731325Z"},"trusted":true},"outputs":[],"source":["# task2 data processing\n","filename_train, x_train, y_train = ExtractData(train_data, root=TRAIN_PATH, task_round=\"task2\")\n","x_train_aug, y_train_aug = dataAugmentation(x_train, y_train)\n","train_ds = TaskDataset(x_train_aug, y_train_aug, filename_train)\n","train_dl = DataLoader(train_ds, batch_size=200, num_workers=2, drop_last=True, shuffle=True)\n","\n","filename_val, x_val, y_val = ExtractData(val_data, root=TRAIN_PATH, task_round=\"task2\")\n","val_ds = TaskDataset(x_val, y_val, filename_val)\n","val_dl = DataLoader(val_ds, batch_size=200, num_workers=2, drop_last=False, shuffle=False)\n","\n","filename_test, x_test, y_test = ExtractData(test_data, root=TEST_PATH, task_round=\"task2\")\n","test_ds = TaskDataset(x_test, y_test, filename_test, return_filename=True)\n","test_dl = DataLoader(test_ds, batch_size=125, num_workers=2, drop_last=False, shuffle=False)"]},{"cell_type":"code","execution_count":267,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T08:51:20.333467Z","iopub.status.busy":"2022-12-18T08:51:20.332758Z","iopub.status.idle":"2022-12-18T08:51:20.347583Z","shell.execute_reply":"2022-12-18T08:51:20.346578Z","shell.execute_reply.started":"2022-12-18T08:51:20.333430Z"},"trusted":true},"outputs":[],"source":["class Model2(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # input size = (3, 32, 32)\n","        self.conv1 = self.conv(1, 64, 3, 1, 1)  # (64,32,32)\n","        self.conv2 = self.conv(64, 64, 3, 1, 1)  # (64,32,32)\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=2)  # (64,16,16)\n","        self.dropout1 = nn.Dropout(p=0.2)\n","\n","        self.conv3 = self.conv(64, 128, 3, 1, 1)  # (128,16,16)\n","        self.conv4 = self.conv(128, 128, 3, 1, 1)  # (128,16,16)\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=2)  # (128,8,8)\n","        self.dropout2 = nn.Dropout(p=0.3)\n","\n","        self.conv5 = self.conv(128, 128, 3, 1, 1)  # (128,8,8)\n","        self.conv6 = self.conv(128, 128, 3, 1, 1)  # (128,8,8)\n","        self.maxpool3 = nn.MaxPool2d(kernel_size=2)  # (128,4,4)\n","        self.dropout3 = nn.Dropout(p=0.4)\n","\n","        # FC, input size = (16, 5, 5)\n","        self.fc11 = nn.Linear(128 * 4 * 4, 512)\n","        self.relu31 = nn.ReLU()\n","        self.dropout41 = nn.Dropout(p=0.5)\n","        self.fc21 = nn.Linear(512, 36*2)\n","        \n","        self.fc12 = nn.Linear(128 * 4 * 4, 512)\n","        self.relu32 = nn.ReLU()\n","        self.dropout42 = nn.Dropout(p=0.5)\n","        self.fc22 = nn.Linear(512, 36*2)\n","        self.output = nn.Softmax(dim=1)\n","\n","    def conv(self, in_c, out_c, kernel_size, stride=1, padding=0):\n","        conv_layer = nn.Sequential(\n","            nn.Conv2d(in_c, out_c, kernel_size=kernel_size,\n","                      stride=stride, padding=padding),\n","            nn.BatchNorm2d(out_c),\n","            nn.ReLU()\n","        )\n","        return conv_layer\n","\n","    def forward(self, x):\n","        out = self.dropout1(self.maxpool1(self.conv2(self.conv1(x))))\n","        out = self.dropout2(self.maxpool2(self.conv4(self.conv3(out))))\n","        out = self.dropout3(self.maxpool3(self.conv6(self.conv5(out))))\n","        out = torch.flatten(out, 1)  # from CNN to FCN\n","        out1 = self.output(self.fc21(self.dropout41(self.relu31(self.fc11(out)))))\n","        out2 = self.output(self.fc22(self.dropout42(self.relu32(self.fc12(out)))))\n","        return out1, out2"]},{"cell_type":"code","execution_count":299,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T09:00:03.418556Z","iopub.status.busy":"2022-12-18T09:00:03.418168Z","iopub.status.idle":"2022-12-18T09:02:59.112374Z","shell.execute_reply":"2022-12-18T09:02:59.110351Z","shell.execute_reply.started":"2022-12-18T09:00:03.418524Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0]\n","accuracy (validation): tensor(0.0627, device='cuda:0')\n","Epoch [1]\n","accuracy (validation): tensor(0.0904, device='cuda:0')\n","Epoch [2]\n","accuracy (validation): tensor(0.1286, device='cuda:0')\n","Epoch [3]\n","accuracy (validation): tensor(0.1201, device='cuda:0')\n","Epoch [4]\n","accuracy (validation): tensor(0.1570, device='cuda:0')\n","Epoch [5]\n","accuracy (validation): tensor(0.1992, device='cuda:0')\n","Epoch [6]\n","accuracy (validation): tensor(0.2619, device='cuda:0')\n","Epoch [7]\n","accuracy (validation): tensor(0.2685, device='cuda:0')\n","Epoch [8]\n","accuracy (validation): tensor(0.2856, device='cuda:0')\n","Epoch [9]\n","accuracy (validation): tensor(0.3443, device='cuda:0')\n","Epoch [10]\n","accuracy (validation): tensor(0.3621, device='cuda:0')\n","Epoch [11]\n","accuracy (validation): tensor(0.3806, device='cuda:0')\n","Epoch [12]\n","accuracy (validation): tensor(0.4004, device='cuda:0')\n","Epoch [13]\n","accuracy (validation): tensor(0.3964, device='cuda:0')\n","Epoch [14]\n","accuracy (validation): tensor(0.4162, device='cuda:0')\n","Epoch [15]\n","accuracy (validation): tensor(0.4505, device='cuda:0')\n","Epoch [16]\n","accuracy (validation): tensor(0.4664, device='cuda:0')\n","Epoch [17]\n","accuracy (validation): tensor(0.4650, device='cuda:0')\n","Epoch [18]\n","accuracy (validation): tensor(0.4828, device='cuda:0')\n","Epoch [19]\n","accuracy (validation): tensor(0.4967, device='cuda:0')\n","Epoch [20]\n","accuracy (validation): tensor(0.5145, device='cuda:0')\n","Epoch [21]\n","accuracy (validation): tensor(0.5350, device='cuda:0')\n","Epoch [22]\n","accuracy (validation): tensor(0.5251, device='cuda:0')\n","Epoch [23]\n","accuracy (validation): tensor(0.5613, device='cuda:0')\n","Epoch [24]\n","accuracy (validation): tensor(0.5956, device='cuda:0')\n","Epoch [25]\n","accuracy (validation): tensor(0.5772, device='cuda:0')\n","Epoch [26]\n","accuracy (validation): tensor(0.5871, device='cuda:0')\n","Epoch [27]\n","accuracy (validation): tensor(0.6537, device='cuda:0')\n","Epoch [28]\n","accuracy (validation): tensor(0.6649, device='cuda:0')\n","Epoch [29]\n","accuracy (validation): tensor(0.6609, device='cuda:0')\n","Epoch [30]\n","accuracy (validation): tensor(0.6570, device='cuda:0')\n","Epoch [31]\n","accuracy (validation): tensor(0.6801, device='cuda:0')\n","Epoch [32]\n","accuracy (validation): tensor(0.6959, device='cuda:0')\n","Epoch [33]\n","accuracy (validation): tensor(0.7058, device='cuda:0')\n","Epoch [34]\n","accuracy (validation): tensor(0.6979, device='cuda:0')\n","Epoch [35]\n","accuracy (validation): tensor(0.6801, device='cuda:0')\n","Epoch [36]\n","accuracy (validation): tensor(0.6953, device='cuda:0')\n","Epoch [37]\n","accuracy (validation): tensor(0.7091, device='cuda:0')\n","Epoch [38]\n","accuracy (validation): tensor(0.7296, device='cuda:0')\n","Epoch [39]\n","accuracy (validation): tensor(0.6887, device='cuda:0')\n","Epoch [40]\n","accuracy (validation): tensor(0.7632, device='cuda:0')\n","Epoch [41]\n","accuracy (validation): tensor(0.7487, device='cuda:0')\n","Epoch [42]\n","accuracy (validation): tensor(0.7665, device='cuda:0')\n","Epoch [43]\n","accuracy (validation): tensor(0.7639, device='cuda:0')\n","Epoch [44]\n","accuracy (validation): tensor(0.7797, device='cuda:0')\n","Epoch [45]\n","accuracy (validation): tensor(0.7685, device='cuda:0')\n","Epoch [46]\n","accuracy (validation): tensor(0.7889, device='cuda:0')\n","Epoch [47]\n","accuracy (validation): tensor(0.7606, device='cuda:0')\n","Epoch [48]\n","accuracy (validation): tensor(0.7856, device='cuda:0')\n","Epoch [49]\n","accuracy (validation): tensor(0.8100, device='cuda:0')\n","Epoch [50]\n","accuracy (validation): tensor(0.8061, device='cuda:0')\n","Epoch [51]\n","accuracy (validation): tensor(0.8179, device='cuda:0')\n","Epoch [52]\n","accuracy (validation): tensor(0.7962, device='cuda:0')\n","Epoch [53]\n","accuracy (validation): tensor(0.8120, device='cuda:0')\n","Epoch [54]\n","accuracy (validation): tensor(0.8047, device='cuda:0')\n","Epoch [55]\n","accuracy (validation): tensor(0.8219, device='cuda:0')\n","Epoch [56]\n","accuracy (validation): tensor(0.8206, device='cuda:0')\n","Epoch [57]\n","accuracy (validation): tensor(0.7817, device='cuda:0')\n","Epoch [58]\n","accuracy (validation): tensor(0.8364, device='cuda:0')\n","Epoch [59]\n","accuracy (validation): tensor(0.8173, device='cuda:0')\n","Epoch [60]\n","accuracy (validation): tensor(0.8450, device='cuda:0')\n","Epoch [61]\n","accuracy (validation): tensor(0.7718, device='cuda:0')\n","Epoch [62]\n","accuracy (validation): tensor(0.8364, device='cuda:0')\n","Epoch [63]\n","accuracy (validation): tensor(0.8351, device='cuda:0')\n","Epoch [64]\n","accuracy (validation): tensor(0.8562, device='cuda:0')\n","Epoch [65]\n","accuracy (validation): tensor(0.8443, device='cuda:0')\n","Epoch [66]\n","accuracy (validation): tensor(0.8107, device='cuda:0')\n","Epoch [67]\n","accuracy (validation): tensor(0.8575, device='cuda:0')\n","Epoch [68]\n","accuracy (validation): tensor(0.8423, device='cuda:0')\n","Epoch [69]\n","accuracy (validation): tensor(0.7988, device='cuda:0')\n","Epoch [70]\n","accuracy (validation): tensor(0.8061, device='cuda:0')\n","Epoch [71]\n","accuracy (validation): tensor(0.8714, device='cuda:0')\n","Epoch [72]\n","accuracy (validation): tensor(0.8569, device='cuda:0')\n","Epoch [73]\n","accuracy (validation): tensor(0.8839, device='cuda:0')\n","Epoch [74]\n","accuracy (validation): tensor(0.8410, device='cuda:0')\n","Epoch [75]\n","accuracy (validation): tensor(0.8206, device='cuda:0')\n","Epoch [76]\n","accuracy (validation): tensor(0.8826, device='cuda:0')\n","Epoch [77]\n","accuracy (validation): tensor(0.8674, device='cuda:0')\n","Epoch [78]\n","accuracy (validation): tensor(0.8852, device='cuda:0')\n","Epoch [79]\n","accuracy (validation): tensor(0.8707, device='cuda:0')\n","Epoch [80]\n","accuracy (validation): tensor(0.8799, device='cuda:0')\n","Epoch [81]\n","accuracy (validation): tensor(0.8852, device='cuda:0')\n","Epoch [82]\n","accuracy (validation): tensor(0.8951, device='cuda:0')\n","Epoch [83]\n","accuracy (validation): tensor(0.9004, device='cuda:0')\n","Epoch [84]\n","accuracy (validation): tensor(0.8991, device='cuda:0')\n","Epoch [85]\n","accuracy (validation): tensor(0.9077, device='cuda:0')\n","Epoch [86]\n","accuracy (validation): tensor(0.9255, device='cuda:0')\n","Epoch [87]\n","accuracy (validation): tensor(0.9215, device='cuda:0')\n","Epoch [88]\n","accuracy (validation): tensor(0.9202, device='cuda:0')\n","Epoch [89]\n","accuracy (validation): tensor(0.9195, device='cuda:0')\n","Epoch [90]\n","accuracy (validation): tensor(0.9175, device='cuda:0')\n","Epoch [91]\n","accuracy (validation): tensor(0.8212, device='cuda:0')\n","Epoch [92]\n","accuracy (validation): tensor(0.9109, device='cuda:0')\n","Epoch [93]\n","accuracy (validation): tensor(0.8938, device='cuda:0')\n","Epoch [94]\n","accuracy (validation): tensor(0.9433, device='cuda:0')\n","Epoch [95]\n","accuracy (validation): tensor(0.9499, device='cuda:0')\n","Epoch [96]\n","accuracy (validation): tensor(0.9367, device='cuda:0')\n","Epoch [97]\n","accuracy (validation): tensor(0.9472, device='cuda:0')\n","Epoch [98]\n","accuracy (validation): tensor(0.9406, device='cuda:0')\n","Epoch [99]\n","accuracy (validation): tensor(0.9479, device='cuda:0')\n"]}],"source":["model = Model2().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","\n","for epoch in range(100):\n","    print(f\"Epoch [{epoch}]\")\n","    model.train()\n","    for image, label in train_dl:\n","        image = image.to(device)\n","        label = label.to(device)\n","        \n","        pred = model(image)\n","        \n","        label = label.long()\n","        loss1 = loss_fn(pred[0], label[:,0])\n","        loss2 = loss_fn(pred[1], label[:,1])\n","        loss = loss1 + loss2\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    sample_count = 0\n","    correct_count = 0\n","    model.eval()\n","    for image, label in val_dl:\n","        image = image.to(device)\n","        label = label.to(device)\n","        \n","        pred = model(image)\n","        \n","        pred1 = torch.argmax(pred[0], dim=1)\n","        pred2 = torch.argmax(pred[1], dim=1)\n","        \n","        sample_count += 2*len(image)\n","        correct_count += (label[:,0] == pred1).sum()\n","        correct_count += (label[:,1] == pred2).sum()\n","        \n","    print(\"accuracy (validation):\", correct_count / sample_count)"]},{"cell_type":"code","execution_count":300,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T09:03:03.034195Z","iopub.status.busy":"2022-12-18T09:03:03.033763Z","iopub.status.idle":"2022-12-18T09:03:03.450059Z","shell.execute_reply":"2022-12-18T09:03:03.448741Z","shell.execute_reply.started":"2022-12-18T09:03:03.034158Z"},"trusted":true},"outputs":[],"source":["# predict test2 write to csv\n","if os.path.exists('submission.csv'):\n","    csv_writer = csv.writer(open('submission.csv', 'a', newline=''))\n","else:\n","    csv_writer = csv.writer(open('submission.csv', 'w', newline=''))\n","    csv_writer.writerow([\"filename\", \"label\"])\n","\n","\n","model.eval()\n","for image, filenames in test_dl:\n","    image = image.to(device)\n","    \n","    pred = model(image)\n","    pred1 = torch.argmax(pred[0], dim=1)\n","    pred2 = torch.argmax(pred[1], dim=1)\n","    for i in range(len(filenames)):\n","        cur_string = decode[pred1[i].item()]+decode[pred2[i].item()]\n","        csv_writer.writerow([filenames[i], cur_string])"]},{"cell_type":"code","execution_count":301,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T09:03:06.954083Z","iopub.status.busy":"2022-12-18T09:03:06.952937Z","iopub.status.idle":"2022-12-18T09:03:07.081733Z","shell.execute_reply":"2022-12-18T09:03:07.080703Z","shell.execute_reply.started":"2022-12-18T09:03:06.954036Z"},"trusted":true},"outputs":[],"source":["task2 = {'model': Model2(),\n","         'state_dict': model.state_dict(),\n","         'optimizer' : optimizer.state_dict()}\n","\n","torch.save(task2, 'task2.pth')"]},{"cell_type":"code","execution_count":302,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T09:03:09.962248Z","iopub.status.busy":"2022-12-18T09:03:09.961853Z","iopub.status.idle":"2022-12-18T09:03:18.717844Z","shell.execute_reply":"2022-12-18T09:03:18.716787Z","shell.execute_reply.started":"2022-12-18T09:03:09.962215Z"},"trusted":true},"outputs":[],"source":["# task3 data processing\n","filename_train, x_train, y_train = ExtractData(train_data, root=TRAIN_PATH, task_round=\"task3\")\n","x_train_aug, y_train_aug = dataAugmentation(x_train, y_train)\n","train_ds = TaskDataset(x_train_aug, y_train_aug, filename_train)\n","train_dl = DataLoader(train_ds, batch_size=240, num_workers=2, drop_last=True, shuffle=True)\n","\n","filename_val, x_val, y_val = ExtractData(val_data, root=TRAIN_PATH, task_round=\"task3\")\n","val_ds = TaskDataset(x_val, y_val, filename_val)\n","val_dl = DataLoader(val_ds, batch_size=240, num_workers=2, drop_last=False, shuffle=False)\n","\n","filename_test, x_test, y_test = ExtractData(test_data, root=TEST_PATH, task_round=\"task3\")\n","test_ds = TaskDataset(x_test, y_test, filename_test, return_filename=True)\n","test_dl = DataLoader(test_ds, batch_size=20, num_workers=2, drop_last=False, shuffle=False)"]},{"cell_type":"code","execution_count":303,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T09:03:46.072151Z","iopub.status.busy":"2022-12-18T09:03:46.070919Z","iopub.status.idle":"2022-12-18T09:03:46.090633Z","shell.execute_reply":"2022-12-18T09:03:46.089657Z","shell.execute_reply.started":"2022-12-18T09:03:46.072106Z"},"trusted":true},"outputs":[],"source":["class Model3(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # input size = (3, 32, 32)\n","        self.conv1 = self.conv(1, 64, 3, 1, 1)  # (64,32,32)\n","        self.conv2 = self.conv(64, 64, 3, 1, 1)  # (64,32,32)\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=2)  # (64,16,16)\n","        self.dropout1 = nn.Dropout(p=0.2)\n","\n","        self.conv3 = self.conv(64, 128, 3, 1, 1)  # (128,16,16)\n","        self.conv4 = self.conv(128, 128, 3, 1, 1)  # (128,16,16)\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=2)  # (128,8,8)\n","        self.dropout2 = nn.Dropout(p=0.3)\n","\n","        self.conv5 = self.conv(128, 128, 3, 1, 1)  # (128,8,8)\n","        self.conv6 = self.conv(128, 128, 3, 1, 1)  # (128,8,8)\n","        self.maxpool3 = nn.MaxPool2d(kernel_size=2)  # (128,4,4)\n","        self.dropout3 = nn.Dropout(p=0.4)\n","\n","        # FC, input size = (16, 5, 5)\n","        self.fc11 = nn.Linear(128 * 4 * 4, 512)\n","        self.relu31 = nn.ReLU()\n","        self.dropout41 = nn.Dropout(p=0.5)\n","        self.fc21 = nn.Linear(512, 36*4)\n","        \n","        self.fc12 = nn.Linear(128 * 4 * 4, 512)\n","        self.relu32 = nn.ReLU()\n","        self.dropout42 = nn.Dropout(p=0.5)\n","        self.fc22 = nn.Linear(512, 36*4)\n","        \n","        self.fc13 = nn.Linear(128 * 4 * 4, 512)\n","        self.relu33 = nn.ReLU()\n","        self.dropout43 = nn.Dropout(p=0.5)\n","        self.fc23 = nn.Linear(512, 36*4)\n","        \n","        self.fc14 = nn.Linear(128 * 4 * 4, 512)\n","        self.relu34 = nn.ReLU()\n","        self.dropout44 = nn.Dropout(p=0.5)\n","        self.fc24 = nn.Linear(512, 36*4)\n","        self.output = nn.Softmax(dim=1)\n","\n","    def conv(self, in_c, out_c, kernel_size, stride=1, padding=0):\n","        conv_layer = nn.Sequential(\n","            nn.Conv2d(in_c, out_c, kernel_size=kernel_size,\n","                      stride=stride, padding=padding),\n","            nn.BatchNorm2d(out_c),\n","            nn.ReLU()\n","        )\n","        return conv_layer\n","\n","    def forward(self, x):\n","        out = self.dropout1(self.maxpool1(self.conv2(self.conv1(x))))\n","        out = self.dropout2(self.maxpool2(self.conv4(self.conv3(out))))\n","        out = self.dropout3(self.maxpool3(self.conv6(self.conv5(out))))\n","        out = torch.flatten(out, 1)  # from CNN to FCN\n","        out1 = self.output(self.fc21(self.dropout41(self.relu31(self.fc11(out)))))\n","        out2 = self.output(self.fc22(self.dropout42(self.relu32(self.fc12(out)))))\n","        out3 = self.output(self.fc23(self.dropout43(self.relu33(self.fc13(out)))))\n","        out4 = self.output(self.fc24(self.dropout44(self.relu34(self.fc14(out)))))\n","        return out1, out2, out3, out4"]},{"cell_type":"code","execution_count":325,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T09:11:43.934873Z","iopub.status.busy":"2022-12-18T09:11:43.933744Z","iopub.status.idle":"2022-12-18T09:15:22.628610Z","shell.execute_reply":"2022-12-18T09:15:22.626378Z","shell.execute_reply.started":"2022-12-18T09:11:43.934806Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0]\n","accuracy (validation): tensor(0.0392, device='cuda:0')\n","Epoch [1]\n","accuracy (validation): tensor(0.0567, device='cuda:0')\n","Epoch [2]\n","accuracy (validation): tensor(0.0588, device='cuda:0')\n","Epoch [3]\n","accuracy (validation): tensor(0.0703, device='cuda:0')\n","Epoch [4]\n","accuracy (validation): tensor(0.0781, device='cuda:0')\n","Epoch [5]\n","accuracy (validation): tensor(0.0858, device='cuda:0')\n","Epoch [6]\n","accuracy (validation): tensor(0.0982, device='cuda:0')\n","Epoch [7]\n","accuracy (validation): tensor(0.0976, device='cuda:0')\n","Epoch [8]\n","accuracy (validation): tensor(0.1115, device='cuda:0')\n","Epoch [9]\n","accuracy (validation): tensor(0.1175, device='cuda:0')\n","Epoch [10]\n","accuracy (validation): tensor(0.1259, device='cuda:0')\n","Epoch [11]\n","accuracy (validation): tensor(0.1302, device='cuda:0')\n","Epoch [12]\n","accuracy (validation): tensor(0.1365, device='cuda:0')\n","Epoch [13]\n","accuracy (validation): tensor(0.1411, device='cuda:0')\n","Epoch [14]\n","accuracy (validation): tensor(0.1570, device='cuda:0')\n","Epoch [15]\n","accuracy (validation): tensor(0.1630, device='cuda:0')\n","Epoch [16]\n","accuracy (validation): tensor(0.1745, device='cuda:0')\n","Epoch [17]\n","accuracy (validation): tensor(0.1766, device='cuda:0')\n","Epoch [18]\n","accuracy (validation): tensor(0.1696, device='cuda:0')\n","Epoch [19]\n","accuracy (validation): tensor(0.1938, device='cuda:0')\n","Epoch [20]\n","accuracy (validation): tensor(0.2137, device='cuda:0')\n","Epoch [21]\n","accuracy (validation): tensor(0.2157, device='cuda:0')\n","Epoch [22]\n","accuracy (validation): tensor(0.1996, device='cuda:0')\n","Epoch [23]\n","accuracy (validation): tensor(0.2454, device='cuda:0')\n","Epoch [24]\n","accuracy (validation): tensor(0.2376, device='cuda:0')\n","Epoch [25]\n","accuracy (validation): tensor(0.2627, device='cuda:0')\n","Epoch [26]\n","accuracy (validation): tensor(0.2684, device='cuda:0')\n","Epoch [27]\n","accuracy (validation): tensor(0.2762, device='cuda:0')\n","Epoch [28]\n","accuracy (validation): tensor(0.2823, device='cuda:0')\n","Epoch [29]\n","accuracy (validation): tensor(0.2710, device='cuda:0')\n","Epoch [30]\n","accuracy (validation): tensor(0.2944, device='cuda:0')\n","Epoch [31]\n","accuracy (validation): tensor(0.3131, device='cuda:0')\n","Epoch [32]\n","accuracy (validation): tensor(0.3157, device='cuda:0')\n","Epoch [33]\n","accuracy (validation): tensor(0.3194, device='cuda:0')\n","Epoch [34]\n","accuracy (validation): tensor(0.3321, device='cuda:0')\n","Epoch [35]\n","accuracy (validation): tensor(0.3537, device='cuda:0')\n","Epoch [36]\n","accuracy (validation): tensor(0.3629, device='cuda:0')\n","Epoch [37]\n","accuracy (validation): tensor(0.3569, device='cuda:0')\n","Epoch [38]\n","accuracy (validation): tensor(0.3592, device='cuda:0')\n","Epoch [39]\n","accuracy (validation): tensor(0.3626, device='cuda:0')\n","Epoch [40]\n","accuracy (validation): tensor(0.3047, device='cuda:0')\n","Epoch [41]\n","accuracy (validation): tensor(0.3848, device='cuda:0')\n","Epoch [42]\n","accuracy (validation): tensor(0.3488, device='cuda:0')\n","Epoch [43]\n","accuracy (validation): tensor(0.3992, device='cuda:0')\n","Epoch [44]\n","accuracy (validation): tensor(0.4041, device='cuda:0')\n","Epoch [45]\n","accuracy (validation): tensor(0.3966, device='cuda:0')\n","Epoch [46]\n","accuracy (validation): tensor(0.4237, device='cuda:0')\n","Epoch [47]\n","accuracy (validation): tensor(0.4294, device='cuda:0')\n","Epoch [48]\n","accuracy (validation): tensor(0.4444, device='cuda:0')\n","Epoch [49]\n","accuracy (validation): tensor(0.3980, device='cuda:0')\n","Epoch [50]\n","accuracy (validation): tensor(0.4461, device='cuda:0')\n","Epoch [51]\n","accuracy (validation): tensor(0.4516, device='cuda:0')\n","Epoch [52]\n","accuracy (validation): tensor(0.4724, device='cuda:0')\n","Epoch [53]\n","accuracy (validation): tensor(0.4804, device='cuda:0')\n","Epoch [54]\n","accuracy (validation): tensor(0.4747, device='cuda:0')\n","Epoch [55]\n","accuracy (validation): tensor(0.4833, device='cuda:0')\n","Epoch [56]\n","accuracy (validation): tensor(0.4988, device='cuda:0')\n","Epoch [57]\n","accuracy (validation): tensor(0.5124, device='cuda:0')\n","Epoch [58]\n","accuracy (validation): tensor(0.5049, device='cuda:0')\n","Epoch [59]\n","accuracy (validation): tensor(0.5086, device='cuda:0')\n","Epoch [60]\n","accuracy (validation): tensor(0.5089, device='cuda:0')\n","Epoch [61]\n","accuracy (validation): tensor(0.5109, device='cuda:0')\n","Epoch [62]\n","accuracy (validation): tensor(0.5193, device='cuda:0')\n","Epoch [63]\n","accuracy (validation): tensor(0.5179, device='cuda:0')\n","Epoch [64]\n","accuracy (validation): tensor(0.5294, device='cuda:0')\n","Epoch [65]\n","accuracy (validation): tensor(0.5403, device='cuda:0')\n","Epoch [66]\n","accuracy (validation): tensor(0.5409, device='cuda:0')\n","Epoch [67]\n","accuracy (validation): tensor(0.5449, device='cuda:0')\n","Epoch [68]\n","accuracy (validation): tensor(0.5518, device='cuda:0')\n","Epoch [69]\n","accuracy (validation): tensor(0.5602, device='cuda:0')\n","Epoch [70]\n","accuracy (validation): tensor(0.5567, device='cuda:0')\n","Epoch [71]\n","accuracy (validation): tensor(0.5613, device='cuda:0')\n","Epoch [72]\n","accuracy (validation): tensor(0.5703, device='cuda:0')\n","Epoch [73]\n","accuracy (validation): tensor(0.5867, device='cuda:0')\n","Epoch [74]\n","accuracy (validation): tensor(0.5887, device='cuda:0')\n","Epoch [75]\n","accuracy (validation): tensor(0.5850, device='cuda:0')\n","Epoch [76]\n","accuracy (validation): tensor(0.5997, device='cuda:0')\n","Epoch [77]\n","accuracy (validation): tensor(0.6071, device='cuda:0')\n","Epoch [78]\n","accuracy (validation): tensor(0.5939, device='cuda:0')\n","Epoch [79]\n","accuracy (validation): tensor(0.5988, device='cuda:0')\n","Epoch [80]\n","accuracy (validation): tensor(0.6207, device='cuda:0')\n","Epoch [81]\n","accuracy (validation): tensor(0.6158, device='cuda:0')\n","Epoch [82]\n","accuracy (validation): tensor(0.6279, device='cuda:0')\n","Epoch [83]\n","accuracy (validation): tensor(0.6195, device='cuda:0')\n","Epoch [84]\n","accuracy (validation): tensor(0.6233, device='cuda:0')\n","Epoch [85]\n","accuracy (validation): tensor(0.6267, device='cuda:0')\n","Epoch [86]\n","accuracy (validation): tensor(0.6187, device='cuda:0')\n","Epoch [87]\n","accuracy (validation): tensor(0.6313, device='cuda:0')\n","Epoch [88]\n","accuracy (validation): tensor(0.6299, device='cuda:0')\n","Epoch [89]\n","accuracy (validation): tensor(0.6440, device='cuda:0')\n","Epoch [90]\n","accuracy (validation): tensor(0.6362, device='cuda:0')\n","Epoch [91]\n","accuracy (validation): tensor(0.6478, device='cuda:0')\n","Epoch [92]\n","accuracy (validation): tensor(0.6414, device='cuda:0')\n","Epoch [93]\n","accuracy (validation): tensor(0.6446, device='cuda:0')\n","Epoch [94]\n","accuracy (validation): tensor(0.6452, device='cuda:0')\n","Epoch [95]\n","accuracy (validation): tensor(0.6325, device='cuda:0')\n","Epoch [96]\n","accuracy (validation): tensor(0.6503, device='cuda:0')\n","Epoch [97]\n","accuracy (validation): tensor(0.6558, device='cuda:0')\n","Epoch [98]\n","accuracy (validation): tensor(0.6575, device='cuda:0')\n","Epoch [99]\n","accuracy (validation): tensor(0.6653, device='cuda:0')\n"]}],"source":["model = Model3().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","\n","for epoch in range(100):\n","    print(f\"Epoch [{epoch}]\")\n","    model.train()\n","    for image, label in train_dl:\n","        image = image.to(device)\n","        label = label.to(device)\n","        \n","        pred = model(image)\n","\n","        label = label.long()\n","        loss1 = loss_fn(pred[0], label[:,0])\n","        loss2 = loss_fn(pred[1], label[:,1])\n","        loss3 = loss_fn(pred[2], label[:,2])\n","        loss4 = loss_fn(pred[3], label[:,3])\n","        loss = loss1 + loss2 + loss3 + loss4\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    sample_count = 0\n","    correct_count = 0\n","    model.eval()\n","    for image, label in val_dl:\n","        image = image.to(device)\n","        label = label.to(device)\n","        \n","        pred = model(image)\n","        \n","        pred1 = torch.argmax(pred[0], dim=1)\n","        pred2 = torch.argmax(pred[1], dim=1)\n","        pred3 = torch.argmax(pred[2], dim=1)\n","        pred4 = torch.argmax(pred[3], dim=1)\n","        \n","        sample_count += 4*len(image)\n","\n","        correct_count += (label[:,0] == pred1).sum()\n","        correct_count += (label[:,1] == pred2).sum()\n","        correct_count += (label[:,2] == pred3).sum()\n","        correct_count += (label[:,3] == pred4).sum()\n","        \n","    print(\"accuracy (validation):\", correct_count / sample_count)"]},{"cell_type":"code","execution_count":326,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T09:15:26.384486Z","iopub.status.busy":"2022-12-18T09:15:26.383572Z","iopub.status.idle":"2022-12-18T09:15:26.934432Z","shell.execute_reply":"2022-12-18T09:15:26.933007Z","shell.execute_reply.started":"2022-12-18T09:15:26.384428Z"},"trusted":true},"outputs":[],"source":["# predict task3 write to csv\n","csv_writer = csv.writer(open('submission.csv', 'a', newline=''))\n","\n","model.eval()\n","for image, filenames in test_dl:\n","    image = image.to(device)\n","    \n","    pred = model(image)\n","    pred1 = torch.argmax(pred[0], dim=1)\n","    pred2 = torch.argmax(pred[1], dim=1)\n","    pred3 = torch.argmax(pred[2], dim=1)\n","    pred4 = torch.argmax(pred[3], dim=1)\n","    \n","    for i in range(len(filenames)):\n","        cur_string = decode[pred1[i].item()]+decode[pred2[i].item()]+decode[pred3[i].item()]+decode[pred4[i].item()]\n","        csv_writer.writerow([filenames[i], cur_string])\n","        \n","    \"\"\"\n","    for filename, value in filenames:\n","        cur_string = decode[pred1[i].item()]+decode[pred2[i].item()]+decode[pred3[i].item()]+decode[pred4[i].item()]\n","        csv_writer.writerow(filename, value)\n","    \"\"\""]},{"cell_type":"code","execution_count":327,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T09:15:30.837927Z","iopub.status.busy":"2022-12-18T09:15:30.837121Z","iopub.status.idle":"2022-12-18T09:15:31.031653Z","shell.execute_reply":"2022-12-18T09:15:31.030642Z","shell.execute_reply.started":"2022-12-18T09:15:30.837881Z"},"trusted":true},"outputs":[],"source":["task3 = {'model': Model3(),\n","         'state_dict': model.state_dict(),\n","         'optimizer' : optimizer.state_dict()}\n","\n","torch.save(task3, 'task3.pth')"]},{"cell_type":"code","execution_count":328,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T09:15:34.326503Z","iopub.status.busy":"2022-12-18T09:15:34.325751Z","iopub.status.idle":"2022-12-18T09:15:34.333321Z","shell.execute_reply":"2022-12-18T09:15:34.332308Z","shell.execute_reply.started":"2022-12-18T09:15:34.326453Z"},"trusted":true},"outputs":[],"source":["def load_checkpoint(filepath):\n","    checkpoint = torch.load(filepath)\n","    model = checkpoint['model']\n","    model.load_state_dict(checkpoint['state_dict'])\n","    for parameter in model.parameters():\n","        parameter.requires_grad = False\n","    \n","    model.eval()\n","    \n","    return model"]},{"cell_type":"code","execution_count":329,"metadata":{"execution":{"iopub.execute_input":"2022-12-18T09:15:37.920563Z","iopub.status.busy":"2022-12-18T09:15:37.919654Z","iopub.status.idle":"2022-12-18T09:15:38.089746Z","shell.execute_reply":"2022-12-18T09:15:38.088691Z","shell.execute_reply.started":"2022-12-18T09:15:37.920527Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model1(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout1): Dropout(p=0.2, inplace=False)\n","  (conv3): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (conv4): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout2): Dropout(p=0.3, inplace=False)\n","  (conv5): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (conv6): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout3): Dropout(p=0.4, inplace=False)\n","  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n","  (relu3): ReLU()\n","  (dropout4): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=512, out_features=10, bias=True)\n","  (output): Softmax(dim=1)\n",")\n","Model2(\n","  (conv1): Sequential(\n","    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout1): Dropout(p=0.2, inplace=False)\n","  (conv3): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (conv4): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout2): Dropout(p=0.3, inplace=False)\n","  (conv5): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (conv6): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout3): Dropout(p=0.4, inplace=False)\n","  (fc11): Linear(in_features=2048, out_features=512, bias=True)\n","  (relu31): ReLU()\n","  (dropout41): Dropout(p=0.5, inplace=False)\n","  (fc21): Linear(in_features=512, out_features=72, bias=True)\n","  (fc12): Linear(in_features=2048, out_features=512, bias=True)\n","  (relu32): ReLU()\n","  (dropout42): Dropout(p=0.5, inplace=False)\n","  (fc22): Linear(in_features=512, out_features=72, bias=True)\n","  (output): Softmax(dim=1)\n",")\n","Model3(\n","  (conv1): Sequential(\n","    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout1): Dropout(p=0.2, inplace=False)\n","  (conv3): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (conv4): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout2): Dropout(p=0.3, inplace=False)\n","  (conv5): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (conv6): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout3): Dropout(p=0.4, inplace=False)\n","  (fc11): Linear(in_features=2048, out_features=512, bias=True)\n","  (relu31): ReLU()\n","  (dropout41): Dropout(p=0.5, inplace=False)\n","  (fc21): Linear(in_features=512, out_features=144, bias=True)\n","  (fc12): Linear(in_features=2048, out_features=512, bias=True)\n","  (relu32): ReLU()\n","  (dropout42): Dropout(p=0.5, inplace=False)\n","  (fc22): Linear(in_features=512, out_features=144, bias=True)\n","  (fc13): Linear(in_features=2048, out_features=512, bias=True)\n","  (relu33): ReLU()\n","  (dropout43): Dropout(p=0.5, inplace=False)\n","  (fc23): Linear(in_features=512, out_features=144, bias=True)\n","  (fc14): Linear(in_features=2048, out_features=512, bias=True)\n","  (relu34): ReLU()\n","  (dropout44): Dropout(p=0.5, inplace=False)\n","  (fc24): Linear(in_features=512, out_features=144, bias=True)\n","  (output): Softmax(dim=1)\n",")\n"]}],"source":["model1 = load_checkpoint('task1.pth')\n","print(model1)\n","model2 = load_checkpoint('task2.pth')\n","print(model2)\n","model3 = load_checkpoint('task3.pth')\n","print(model3)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
